# M√≥dulo 5: Entradas/Salidas y Conectividad
## **Tema 5.1:** Archivos (CSV, JSON, Excel) y *paths*

> Objetivo: comprender c√≥mo **leer, escribir y procesar** archivos en formatos comunes (CSV, JSON, Excel) y trabajar con **rutas de archivos** de forma robusta y multiplataforma usando `pathlib`. Incluye ejemplos pr√°cticos y buenas pr√°cticas.

---

### üì¶ Dependencias
- **Built‚Äëin:** `csv`, `json`, `pathlib`, `io`, `os`, `gzip`, `zipfile`
- **Opcional (recomendado para an√°lisis de datos):** `pandas`, `openpyxl` (Excel), `pyarrow` (alto rendimiento con CSV/Parquet)


---

## 1) Conceptos clave de I/O en Python

**Context manager (`with`)**: Utilizar `with` al abrir archivos garantiza que se cierren correctamente, incluso si ocurre una excepci√≥n. Esto evita fugas de recursos y errores dif√≠ciles de detectar.

**Codificaci√≥n**: La codificaci√≥n determina c√≥mo se interpretan los caracteres. Usar `encoding="utf-8"` es lo m√°s seguro y compatible, salvo que el archivo provenga de una fuente que indique otra codificaci√≥n (por ejemplo, `latin-1`).

**Delimitadores y locales**: En archivos CSV, el separador de campos puede variar (`;`, `,`, `\t`). Adem√°s, en algunos pa√≠ses el punto y coma se usa como separador decimal. Es importante ajustar los par√°metros `delimiter` y `decimal` para leer correctamente los datos.

**Tipos y fechas**: Al leer datos, especialmente desde archivos, conviene especificar el tipo de cada columna (`dtype`) y c√≥mo interpretar las fechas (`parse_dates`). Esto ayuda a evitar errores y asegura que los datos sean tratados correctamente.

**Tama√±o**: Para archivos muy grandes, no conviene leer todo en memoria. Se recomienda procesar por partes (chunks), usar iteradores, o trabajar con archivos comprimidos (`.gz`, `.zip`) para ahorrar espacio y memoria.

---

## 2) Rutas y *paths* con `pathlib` (multiplataforma)

```python
from pathlib import Path

# Ruta relativa a tu script / notebook
base = Path(".")                # directorio actual
datos_dir = base / "datos"      # crea el path "datos" relativo

# Asegurar que exista
datos_dir.mkdir(parents=True, exist_ok=True)

# Construir rutas seguras (independiente de Windows/Linux/Mac)
csv_path = datos_dir / "ventas.csv"
json_path = datos_dir / "config.json"
xlsx_path = datos_dir / "reporte.xlsx"

# Comprobar existencia y tama√±o
if csv_path.exists():
    print(csv_path.resolve(), csv_path.stat().st_size, "bytes")

# Listar por patr√≥n (globbing)
for f in datos_dir.glob("*.csv"):
    print("CSV encontrado:", f.name)

# Rutas absolutas y de usuario
abs_path = csv_path.resolve()
home_path = Path.home() / "Documentos" / "taller_python"

# Variables de entorno
import os
tmp_dir = Path(os.getenv("TMPDIR") or os.getenv("TEMP") or "/tmp")

# Lectura/Escritura de texto/binario
archivo_txt = datos_dir / "nota.txt"
archivo_txt.write_text("Hola, mundo\n", encoding="utf-8")
print(archivo_txt.read_text(encoding="utf-8"))
```

```python
from pathlib import Path

# Ejemplo de estructura:
# proyecto/
# ‚îú‚îÄ‚îÄ datos/
# ‚îÇ   ‚îú‚îÄ‚îÄ ventas.csv
# ‚îÇ   ‚îî‚îÄ‚îÄ reporte.xlsx
# ‚îú‚îÄ‚îÄ config/
# ‚îÇ   ‚îî‚îÄ‚îÄ config.json
# ‚îî‚îÄ‚îÄ logs/
#     ‚îî‚îÄ‚îÄ app.log

# Acceso a archivos en diferentes niveles:
base = Path('.')
datos_dir = base / 'datos'
config_dir = base / 'config'
logs_dir = base / 'logs'

# Acceder a un archivo en datos/
ventas_path = datos_dir / 'ventas.csv'

# Acceder a un archivo en config/
config_path = config_dir / 'config.json'

# Acceder a un archivo en logs/
log_path = logs_dir / 'app.log'

# Crear carpetas si no existen
for d in [datos_dir, config_dir, logs_dir]:
    d.mkdir(parents=True, exist_ok=True)

# Ejemplo: leer ventas si existe
if ventas_path.exists():
    print('Ventas:', ventas_path.read_text(encoding='utf-8'))

# Ejemplo: escribir un log
log_path.write_text('Inicio de la aplicaci√≥n\n', encoding='utf-8')

# Ejemplo: armar ruta a subcarpeta y archivo
subcarpeta = datos_dir / '2025' / 'enero'
archivo_sub = subcarpeta / 'resumen.csv'
subcarpeta.mkdir(parents=True, exist_ok=True)
archivo_sub.write_text('fecha,total\n2025-01-01,100\n', encoding='utf-8')

# Listar todos los archivos CSV en datos y subcarpetas
for f in datos_dir.rglob('*.csv'):
    print('CSV encontrado:', f.relative_to(base))
```

**Buenas pr√°cticas:**
- Usar `pathlib` en lugar de concatenar strings con `/` o `\`.
- Validar permisos, existencia y espacio disponible en disco si es cr√≠tico.
- Evitar rutas **hardcodeadas**; parametrizar por configuraci√≥n/variables de entorno.

---

## 3) CSV (Comma/; Separated Values)

### 3.1 Leer y escribir CSV con la librer√≠a est√°ndar `csv`

```python
import csv
from pathlib import Path

csv_path = Path("datos/ventas.csv")
csv_path.parent.mkdir(exist_ok=True, parents=True)

# Escribir
rows = [
    {"fecha": "2025-11-01", "producto": "A", "precio": "12.50", "cantidad": "3"},
    {"fecha": "2025-11-01", "producto": "B", "precio": "8,10",  "cantidad": "5"},  # nota: coma decimal
]

with csv_path.open("w", newline="", encoding="utf-8") as f:
    writer = csv.DictWriter(f, fieldnames=["fecha", "producto", "precio", "cantidad"], delimiter=";")
    writer.writeheader()
    writer.writerows(rows)

# Leer
with csv_path.open("r", newline="", encoding="utf-8") as f:
    reader = csv.DictReader(f, delimiter=";")
    for row in reader:
        print(row)
```

**Notas:**
- Usa `newline=""` para evitar l√≠neas en blanco extra en Windows.
- Ajusta `delimiter=";"` si tu CSV usa punto y coma.
- Para comas decimales, conviene normalizar antes de convertir a `float`.

### 3.2 Leer y escribir CSV con `pandas` (librer√≠a externa recomendada para an√°lisis)

```python
import pandas as pd
from pathlib import Path

csv_path = Path("datos/ventas.csv")

# Leer con opciones
df = pd.read_csv(
    csv_path,
    sep=";",           # delimitador
    encoding="utf-8",
    dtype={"producto": "category"},
    parse_dates=["fecha"],
    dayfirst=True,     # si el formato es dd/mm/yyyy
    na_values=["", "NA", "N/A"]
)

# Normalizar decimales si vienen con coma
df["precio"] = (
    df["precio"]
      .astype(str)
      .str.replace(",", ".", regex=False)
      .astype(float)
)

df["importe"] = df["precio"] * df["cantidad"].astype(int)
print(df.head())

# Escribir
salida = Path("datos/ventas_limpias.csv")
df.to_csv(salida, sep=",", index=False, encoding="utf-8")
```

**CSV grande (chunks):**
```python
import pandas as pd

for chunk in pd.read_csv("datos/ventas_grandes.csv", sep=";", chunksize=100_000):
    chunk["importe"] = chunk["precio"] * chunk["cantidad"]
    # procesar / acumular / guardar...
```

**CSV comprimido:**
```python
import pandas as pd
df.to_csv("datos/ventas.csv.gz", index=False, compression="gzip")
```

---

## 4) JSON (estructuras jer√°rquicas)

### 4.1 Usando la librer√≠a est√°ndar `json`

```python
import json
from pathlib import Path

json_path = Path("datos/config.json")

config = {
    "version": 1,
    "origen": "TDF",
    "rutas": {"entrada": "datos/ventas.csv", "salida": "datos/ventas_limpias.csv"},
    "parametros": {"umbral_alerta": 0.8, "activa_cache": True}
}

# Escribir (legible y estable)
json_path.write_text(json.dumps(config, ensure_ascii=False, indent=2, sort_keys=True), encoding="utf-8")

# Leer
cfg = json.loads(json_path.read_text(encoding="utf-8"))
print(cfg["rutas"]["entrada"])
```

**Consejos:**
- `indent` y `sort_keys` ayudan a versionar el JSON en Git.
- Para `decimal` exacto, convertir a `str` o usar `decimal.Decimal` manualmente.

### 4.2 JSON con `pandas`

```python
import pandas as pd
from pathlib import Path

jsonl_path = Path("datos/ventas.jsonl")  # JSON Lines: una fila por l√≠nea
jsonl_path.write_text(
    '{"fecha":"2025-11-01","producto":"A","precio":12.5,"cantidad":3}\n'
    '{"fecha":"2025-11-01","producto":"B","precio":8.1,"cantidad":5}\n',
    encoding="utf-8"
)

df = pd.read_json(jsonl_path, lines=True)
print(df)
```

**Formato JSON Lines** es ideal para logs/ingesta incremental (procesable l√≠nea a l√≠nea).


### 4.3 Convertir estructuras Python a JSON

Para convertir un diccionario, lista, set (convertido a lista) u objeto simple a formato JSON se utiliza `json.dumps()`:

```python
import json

# Diccionario
data_dict = {"nombre": "Ana", "edad": 30}
json_str = json.dumps(data_dict)

# Lista
data_list = [1, 2, 3]
json_str = json.dumps(data_list)

# Set (convertir a lista primero)
data_set = {"a", "b", "c"}
json_str = json.dumps(list(data_set))

# Objeto (usar __dict__ o dataclasses)
class Persona:
    def __init__(self, nombre, edad):
        self.nombre = nombre
        self.edad = edad

p = Persona("Ana", 30)
json_str = json.dumps(p.__dict__)

# Resultado: json_str es un string en formato JSON
print(json_str)
```

---

## 6) XML (formato jer√°rquico)

El formato XML se usa para datos estructurados y configuraciones. En Python se puede trabajar con la librer√≠a est√°ndar `xml.etree.ElementTree`:

```python
import xml.etree.ElementTree as ET

# Crear un √°rbol XML
root = ET.Element("personas")
persona = ET.SubElement(root, "persona")
ET.SubElement(persona, "nombre").text = "Ana"
ET.SubElement(persona, "edad").text = "30"

# Convertir a string
xml_str = ET.tostring(root, encoding="unicode")
print(xml_str)

# Guardar en archivo
with open("datos/personas.xml", "w", encoding="utf-8") as f:
    f.write(xml_str)
```

Para leer XML:

```python
tree = ET.parse("datos/personas.xml")
root = tree.getroot()
for persona in root.findall("persona"):
    print(persona.find("nombre").text, persona.find("edad").text)
```

## 5) Excel (`.xlsx`): hojas m√∫ltiples, formatos, tipos

> Requiere `openpyxl` para lectura/escritura de `.xlsx` con `pandas`.

### 5.1 Exportar a Excel con `pandas`

```python
import pandas as pd
from pathlib import Path

df = pd.DataFrame({
    "fecha": pd.to_datetime(["2025-11-01","2025-11-02"]),
    "producto": ["A","B"],
    "precio": [12.5, 8.1],
    "cantidad": [3, 5]
})
df["importe"] = df["precio"] * df["cantidad"]

xlsx_path = Path("datos/reporte.xlsx")
with pd.ExcelWriter(xlsx_path, engine="openpyxl") as writer:
    df.to_excel(writer, sheet_name="Ventas", index=False)
```

### 5.2 Leer Excel (hoja/s, tipos y fechas)

```python
import pandas as pd
from pathlib import Path

xlsx_path = Path("datos/reporte.xlsx")

df = pd.read_excel(
    xlsx_path,
    sheet_name="Ventas",      # o lista de hojas para dict de DataFrames
    dtype={"producto": "category"},
    parse_dates=["fecha"]
)
print(df.dtypes)
```

### 5.3 Varias hojas y formato de salida

```python
import pandas as pd
from pathlib import Path

resumen = pd.DataFrame({"m√©trica": ["ventas_totales"], "valor": [12345.67]})

with pd.ExcelWriter("datos/informe.xlsx", engine="openpyxl") as writer:
    df.to_excel(writer, sheet_name="Detalle", index=False)
    resumen.to_excel(writer, sheet_name="Resumen", index=False)
```

**Notas:**
- Excel no es ideal para *big data*. Prefiere CSV/Parquet para volumen y reproducibilidad.
- Controlar tipos: Excel puede convertir c√≥digos como `00123` ‚Üí `123`. Guardar como texto cuando corresponda (`dtype=str`).

---

## 6) Errores comunes y *troubleshooting*

- **Caracteres raros/acentos** ‚Üí especificar `encoding="utf-8"` o el correcto (`latin-1`, `cp1252`).  
- **Delimitador incorrecto** ‚Üí probar `sep=";"` vs `","` y `decimal=","` en `pandas`.  
- **Fechas ambiguas** ‚Üí usar `dayfirst=True` o `format` en `to_datetime`.  
- **Memoria insuficiente** ‚Üí `chunksize` en `read_csv`, tipificar `dtype` m√°s compactos (`Int32`, `float32`, `category`).  
- **Celdas mezcladas en Excel** ‚Üí evitar estilos fusionados; limpiar antes de leer.  
- **Saltos de l√≠nea dentro de celdas CSV** ‚Üí usar `quotechar='"'` y `quoting=csv.QUOTE_MINIMAL`.  

---

## 7) Ejemplo integrador (ETL simple)

**Objetivo:** leer CSV crudo con separador `;` y coma decimal, limpiar y exportar a Excel y JSONL.

```python
import pandas as pd
from pathlib import Path

src = Path("datos/ventas.csv")
dst_csv = Path("datos/ventas_limpias.csv")
dst_xlsx = Path("datos/ventas_limpias.xlsx")
dst_jsonl = Path("datos/ventas_limpias.jsonl")

df = pd.read_csv(src, sep=";", encoding="utf-8", parse_dates=["fecha"])
df["precio"] = df["precio"].astype(str).str.replace(",", ".", regex=False).astype(float)
df["cantidad"] = df["cantidad"].astype("Int64")
df["importe"] = df["precio"] * df["cantidad"]

# Guardar CSV limpio
df.to_csv(dst_csv, index=False)

# Guardar Excel
with pd.ExcelWriter(dst_xlsx, engine="openpyxl") as w:
    df.to_excel(w, sheet_name="Ventas", index=False)

# Guardar JSON Lines
with dst_jsonl.open("w", encoding="utf-8") as f:
    for _, row in df.iterrows():
        f.write(row.to_json(force_ascii=False) + "\n")
```

---

## 8) Buenas pr√°cticas generales

- Centralizar **configuraci√≥n de paths** y par√°metros de lectura/escritura.
- Versionar **archivos fuente** y **scripts de transformaci√≥n** (no solo el resultado).
- Documentar **supuestos** (delimitador, codificaci√≥n, esquema de columnas).
- Evitar *Excel-only pipelines*: ofrecer un CSV/JSON adicional reproducible.
- Validar datos al leer (conteo de filas, nulos, rangos razonables).
- Usar **nombres de columnas** en min√∫scula y sin espacios para facilitar c√≥digo.
- Registrar tiempos y tama√±os de archivos para trazabilidad (*logging*).

---

## 9) Snippets r√°pidos

**Detectar delimitador probable (heur√≠stica simple):**
```python
from collections import Counter
from pathlib import Path

def guess_delimiter(path: Path, candidates=(",",";","\t","|")) -> str:
    line = path.read_text(encoding="utf-8", errors="ignore").splitlines()[0]
    counts = {c: line.count(c) for c in candidates}
    return max(counts, key=counts.get)

print(guess_delimiter(Path("datos/ventas.csv")))
```

**Abrir CSV comprimido (.gz) sin descomprimir a disco:**
```python
import gzip
import csv

with gzip.open("datos/ventas.csv.gz", mode="rt", encoding="utf-8", newline="") as f:
    reader = csv.reader(f)
    for row in reader:
        pass  # procesar
```

**Validar esquema de columnas:**
```python
import pandas as pd

esperadas = {"fecha","producto","precio","cantidad"}
df = pd.read_csv("datos/ventas.csv", sep=";")
faltantes = esperadas - set(df.columns)
if faltantes:
    raise ValueError(f"Faltan columnas: {sorted(faltantes)}")
```

---

## 10) Referencias y recursos adicionales

- **Documentaci√≥n oficial Python:**
    - Archivos y I/O: https://docs.python.org/es/3/tutorial/inputoutput.html
    - M√≥dulo `csv`: https://docs.python.org/3/library/csv.html
    - M√≥dulo `json`: https://docs.python.org/3/library/json.html
    - M√≥dulo `pathlib`: https://docs.python.org/3/library/pathlib.html
    - M√≥dulo `xml.etree.ElementTree`: https://docs.python.org/3/library/xml.etree.elementtree.html
    - Real Python: https://realpython.com/
    - PyBites: https://codechalleng.es/bites/
    - W3Schools Python File Handling: https://www.w3schools.com/python/python_file_handling.asp
    - "Automate the Boring Stuff with Python" (Al Sweigart) - https://automatetheboringstuff.com/
    - "Python Cookbook" (David Beazley, Brian K. Jones)
    - YouTube: Corey Schafer (playlist Python) https://www.youtube.com/playlist?list=PL-osiE80TeTsqhIuOqKhwlXsIBIdSeYtc
    - Curso Python en espa√±ol: https://www.youtube.com/playlist?list=PLlrxD0HtieHhZ9qCJN8Qq7G8f8p6bCk8l