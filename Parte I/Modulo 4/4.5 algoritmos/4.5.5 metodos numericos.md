# üß© M√≥dulo 4: Estructuras de Datos y Algoritmos B√°sicos
## **Secci√≥n 5: Algoritmos Num√©ricos y de Optimizaci√≥n**

---

### üß† Introducci√≥n General

Los **algoritmos num√©ricos y de optimizaci√≥n** son herramientas clave para resolver problemas continuos y discretos donde se busca un valor √≥ptimo o una soluci√≥n aproximada a sistemas de ecuaciones.
Se aplican en ingenier√≠a, f√≠sica, econom√≠a, aprendizaje autom√°tico y an√°lisis de datos.

---

## üîπ 5.1. M√©todo de Gauss-Jordan

**Objetivo / Aplicaci√≥n:**
Resolver sistemas lineales de ecuaciones mediante eliminaci√≥n directa, transformando la matriz aumentada en forma reducida.

**Fundamento te√≥rico:**
Usa operaciones elementales sobre filas hasta convertir la matriz en la **matriz identidad**, obteniendo las soluciones directamente.
**Complejidad temporal:** O(n¬≥) ¬∑ **Espacial:** O(n¬≤)
**Clasificaci√≥n:** Algebra lineal / Determin√≠stico / Directo
**Origen:** Generalizado por **Wilhelm Jordan (1887)**, basado en el m√©todo de **Carl Friedrich Gauss**.

```mermaid
flowchart TD
A[Inicio] --> B[Formar matriz aumentada A|b]
B --> C[Para cada fila pivotear]
C --> D[Normalizar pivote a 1]
D --> E[Eliminar valores en la misma columna]
E --> F[Continuar hasta identidad]
F --> G[Leer soluciones]
```

```python
def gauss_jordan(a, b):
    n = len(a)
    for i in range(n):
        # normalizar pivote
        factor = a[i][i]
        a[i] = [x / factor for x in a[i]]
        b[i] /= factor
        # eliminar resto de la columna
        for j in range(n):
            if j != i:
                factor = a[j][i]
                a[j] = [a[j][k] - factor * a[i][k] for k in range(n)]
                b[j] -= factor * b[i]
    return b

A = [[2,1,-1],[-3,-1,2],[-2,1,2]]
b = [8,-11,-3]
print("Soluci√≥n:", gauss_jordan(A,b))
```

---

## üîπ 5.2. Descomposici√≥n LU

**Objetivo / Aplicaci√≥n:**
Descomponer una matriz A en el producto de una matriz **L (triangular inferior)** y **U (triangular superior)** para resolver sistemas lineales con m√∫ltiples t√©rminos independientes eficientemente.

**Fundamento te√≥rico:**
Permite resolver A¬∑x = b mediante dos sustituciones sucesivas:
1. L¬∑y = b
2. U¬∑x = y
**Complejidad temporal:** O(n¬≥) ¬∑ **Espacial:** O(n¬≤)
**Clasificaci√≥n:** Algebra lineal / Determin√≠stico / Directo
**Origen:** Desarrollado por **Tadeusz Banachiewicz (1938)**.

```mermaid
flowchart TD
A[Inicio] --> B[Inicializar L,U vac√≠as]
B --> C[Factorizar A en L y U]
C --> D[Resolver L¬∑y=b]
D --> E[Resolver U¬∑x=y]
E --> F[Obtener soluci√≥n]
```

```python
def lu_decomposition(A):
    n = len(A)
    L = [[0]*n for _ in range(n)]
    U = [[0]*n for _ in range(n)]
    for i in range(n):
        L[i][i] = 1
        for j in range(i, n):
            U[i][j] = A[i][j] - sum(L[i][k]*U[k][j] for k in range(i))
        for j in range(i+1, n):
            L[j][i] = (A[j][i] - sum(L[j][k]*U[k][i] for k in range(i))) / U[i][i]
    return L, U

A = [[4,3],[6,3]]
L,U = lu_decomposition(A)
print("L=",L)
print("U=",U)
```

---

## üîπ 5.3. Descenso del Gradiente (Gradient Descent)

**Objetivo / Aplicaci√≥n:**
Minimizar una funci√≥n ajustando iterativamente sus par√°metros en direcci√≥n opuesta al gradiente.
Usado en **machine learning** y **optimizaci√≥n num√©rica**.

**Fundamento te√≥rico:**
Actualiza `x := x - Œ± * ‚àáf(x)` hasta converger a un m√≠nimo local.
**Complejidad temporal:** O(k¬∑n) (k = iteraciones) ¬∑ **Espacial:** O(n)
**Clasificaci√≥n:** Num√©rico / Iterativo / Aproximado
**Origen:** **Augustin-Louis Cauchy (1847)**.

```mermaid
flowchart TD
A[Inicio] --> B[Inicializar x, tasa de aprendizaje Œ±]
B --> C[Calcular gradiente ‚àáf(x)]
C --> D[Actualizar x = x - Œ±‚àáf(x)]
D --> E{Convergencia?}
E -->|No| C
E -->|S√≠| F[Retornar m√≠nimo]
```

```python
def gradient_descent(f, df, x0, alpha=0.1, tol=1e-6, max_iter=100):
    x = x0
    for _ in range(max_iter):
        grad = df(x)
        x_new = x - alpha * grad
        if abs(x_new - x) < tol:
            break
        x = x_new
    return x

f = lambda x: (x-3)**2
df = lambda x: 2*(x-3)
print("M√≠nimo aproximado:", gradient_descent(f, df, x0=0))
```

---

## üîπ 5.4. Recocido Simulado (Simulated Annealing)

**Objetivo / Aplicaci√≥n:**
Buscar soluciones aproximadas globales evitando m√≠nimos locales mediante **aleatoriedad controlada**. Inspirado en procesos de **enfriamiento met√°lico**.

**Fundamento te√≥rico:**
Acepta soluciones peores con probabilidad `p = exp(-ŒîE/T)`, disminuyendo la temperatura `T` gradualmente.
**Complejidad temporal:** Dependiente del esquema de enfriamiento.
**Clasificaci√≥n:** Probabil√≠stico / Metaheur√≠stico / Aproximado
**Origen:** **Kirkpatrick, Gelatt y Vecchi (1983)**.

```mermaid
flowchart TD
A[Inicio] --> B[Generar soluci√≥n inicial]
B --> C[Evaluar costo E]
C --> D[Modificar soluci√≥n -> E']
D --> E{E' < E o p<rand()?}
E -->|S√≠| F[Aceptar nueva soluci√≥n]
E -->|No| G[Rechazar]
F --> H[Reducir temperatura]
H --> C
```

```python
import math, random

def simulated_annealing(func, x0, T=1.0, cooling=0.95, min_T=1e-3):
    x = x0
    best = x
    while T > min_T:
        new_x = x + random.uniform(-1, 1)
        delta = func(new_x) - func(x)
        if delta < 0 or math.exp(-delta/T) > random.random():
            x = new_x
        if func(x) < func(best):
            best = x
        T *= cooling
    return best

f = lambda x: (x-2)**2 + 3
print("M√≠nimo aproximado:", simulated_annealing(f, 10))
```

---

## üîπ 5.5. Algoritmos Gen√©ticos

**Objetivo / Aplicaci√≥n:**
Resolver problemas de optimizaci√≥n mediante **simulaci√≥n evolutiva**, usando operadores de **selecci√≥n, cruce y mutaci√≥n**.

**Fundamento te√≥rico:**
Modela la evoluci√≥n de una poblaci√≥n de soluciones hacia mejores individuos.
**Complejidad temporal:** O(g¬∑n¬∑f) (g=generaciones, n=tama√±o poblaci√≥n, f=costo fitness)
**Clasificaci√≥n:** Metaheur√≠stico / Probabil√≠stico / Evolutivo
**Origen:** **John Holland (1975)**.

```mermaid
flowchart TD
A[Inicializar poblaci√≥n] --> B[Evaluar fitness]
B --> C[Seleccionar padres]
C --> D[Cruce y mutaci√≥n]
D --> E[Generar nueva poblaci√≥n]
E --> F{Criterio de parada?}
F -->|No| B
F -->|S√≠| G[Mejor individuo]
```

```python
import random

def genetic_algorithm(fitness, n_gen=50, pop_size=10):
    pop = [random.uniform(-10,10) for _ in range(pop_size)]
    for _ in range(n_gen):
        pop = sorted(pop, key=fitness)
        next_gen = pop[:2]
        while len(next_gen) < pop_size:
            p1, p2 = random.sample(pop[:5], 2)
            child = (p1+p2)/2 + random.uniform(-1,1)
            next_gen.append(child)
        pop = next_gen
    return min(pop, key=fitness)

f = lambda x: (x-4)**2 + 2
print("Mejor valor:", genetic_algorithm(f))
```

---

## üîπ 5.6. M√©todo Simplex (Programaci√≥n Lineal)

**Objetivo / Aplicaci√≥n:**
Resolver **problemas de optimizaci√≥n lineal**: maximizar o minimizar una funci√≥n sujeta a restricciones lineales.

**Fundamento te√≥rico:**
Explora v√©rtices del politopo factible movi√©ndose en direcci√≥n de mejora del objetivo.
**Complejidad temporal:** Promedio polin√≥mica, peor caso exponencial ¬∑ **Espacial:** O(n¬≤)
**Clasificaci√≥n:** Determin√≠stico / Optimizaci√≥n lineal / Iterativo
**Origen:** **George Dantzig (1947)**.

```mermaid
flowchart TD
A[Inicio] --> B[Formular problema est√°ndar]
B --> C[Identificar variable b√°sica]
C --> D[Calcular fila pivote]
D --> E[Actualizar tabla Simplex]
E --> F{√ìptimo alcanzado?}
F -->|No| C
F -->|S√≠| G[Fin]
```

```python
# Ejemplo simplificado con 2 variables y 3 restricciones

def simplex_example():
    # Maximizar z = 3x + 2y sujeto a:
    # x + y <= 4, x <= 2, y <= 3
    best = (0,0)
    max_z = 0
    for x in range(3):
        for y in range(4):
            if x + y <= 4 and x <= 2 and y <= 3:
                z = 3*x + 2*y
                if z > max_z:
                    max_z = z
                    best = (x,y)
    return best, max_z

print("√ìptimo:", simplex_example())
```

---

### ‚úÖ Cierre de la Secci√≥n 5

Los algoritmos num√©ricos y de optimizaci√≥n permiten resolver desde ecuaciones lineales hasta modelos de decisi√≥n complejos.
- **Gauss-Jordan / LU:** resoluci√≥n exacta.
- **Gradient Descent:** b√∫squeda de m√≠nimos.
- **Simulated Annealing / Gen√©ticos:** exploraci√≥n global.
- **Simplex:** optimizaci√≥n lineal cl√°sica.

---
