# üß© M√≥dulo 4: Estructuras de Datos y Algoritmos B√°sicos
## **Secci√≥n 0: Algoritmos Te√≥ricos y Complejidad**

---

### üß† Introducci√≥n General

La **teor√≠a de la complejidad algor√≠tmica** estudia cu√°n eficiente es un algoritmo en t√©rminos de **tiempo de ejecuci√≥n** y **uso de memoria**.
Permite comparar estrategias de resoluci√≥n y estimar su escalabilidad al crecer el tama√±o de los datos.

---

## üîπ 0.1. Complejidad Algor√≠tmica (Big O, Œ©, Œò)

**Objetivo / Aplicaci√≥n:**
Describir el comportamiento asint√≥tico de un algoritmo seg√∫n el tama√±o de entrada `n`.

### üìö Fundamento Te√≥rico

La **notaci√≥n asint√≥tica** proporciona un lenguaje matem√°tico formal para describir el crecimiento de funciones que representan el comportamiento de algoritmos. Este an√°lisis se centra en el comportamiento cuando el tama√±o de entrada tiende al infinito, ignorando constantes multiplicativas y t√©rminos de menor orden.

#### Definiciones Formales:

**1. Big O (O) - Cota Superior Asint√≥tica:**
Formalmente, decimos que $f(n) = O(g(n))$ si existen constantes positivas $c$ y $n‚ÇÄ$ tales que:
```
0 ‚â§ f(n) ‚â§ c¬∑g(n) para todo n ‚â• n‚ÇÄ
```
Esto significa que g(n) es una **cota superior** del crecimiento de f(n), representando el **peor caso** del algoritmo.

**2. Big Omega (Œ©) - Cota Inferior Asint√≥tica:**
Decimos que $f(n) = Œ©(g(n))$ si existen constantes positivas $c$ y $n‚ÇÄ$ tales que:
```
0 ‚â§ c¬∑g(n) ‚â§ f(n) para todo n ‚â• n‚ÇÄ
```
$g(n)$ es una **cota inferior** del crecimiento de $f(n)$, representando el **mejor caso** del algoritmo.

**3. Theta (Œò) - Cota Ajustada:**
Decimos que $f(n) = Œò(g(n))$ si existen constantes positivas $c‚ÇÅ$, $c‚ÇÇ$ y $n‚ÇÄ$ tales que:
```
0 ‚â§ c‚ÇÅ¬∑g(n) ‚â§ f(n) ‚â§ c‚ÇÇ¬∑g(n) para todo n ‚â• n‚ÇÄ
```
$f(n)$ crece al **mismo ritmo** que $g(n)$, representando el **caso promedio** ajustado.

#### Propiedades Fundamentales:

- **Transitividad:** Si $f(n) = O(g(n))$ y $g(n) = O(h(n))$, entonces $f(n) = O(h(n))$
- **Reflexividad:** $f(n) = O(f(n))$
- **Simetr√≠a (para Œò):** Si $f(n) = Œò(g(n))$, entonces $g(n) = Œò(f(n))$
- **Relaci√≥n entre notaciones:** $f(n) = Œò(g(n)) ‚ü∫ f(n) = O(g(n))$ y $f(n) = Œ©(g(n))$

#### Jerarqu√≠a de Complejidades:

```
O(1) < O(log log n) < O(log n) < O(‚àön) < O(n) < O(n log n) <
O(n¬≤) < O(n¬≥) < O(2‚Åø) < O(n!) < O(n‚Åø)
```

**Implicaciones Pr√°cticas:**
- Algoritmos $O(1)$ y $O(log n)$: escalan excelentemente
- $O(n)$ y $O(n log n)$: aceptables para grandes vol√∫menes
- $O(n¬≤)$ y $O(n¬≥)$: problem√°ticos con datos masivos
- $O(2‚Åø)$ y $O(n!)$: solo viables para entradas peque√±as

#### An√°lisis de Complejidad Espacial:

Adem√°s del tiempo, analizamos el **espacio** (memoria) que requiere un algoritmo:
- **In-place:** $O(1)$ espacio adicional (modifica estructura original)
- **Recursi√≥n:** $O(h)$ donde h es la altura de recursi√≥n
- **Memorizaci√≥n:** Espacio proporcional a subproblemas √∫nicos

- **O (Big O):** cota superior (peor caso).
- **Œ© (Omega):** cota inferior (mejor caso).
- **Œò (Theta):** cota ajustada (caso promedio).

| Complejidad | Ejemplo t√≠pico | Descripci√≥n |
|--------------|----------------|--------------|
| O(1) | Acceso en arreglo | Tiempo constante |
| O(log n) | B√∫squeda binaria | Crece lentamente |
| O(n) | Recorrido de lista | Lineal |
| O(n log n) | MergeSort | Eficiente |
| O(n¬≤) | BubbleSort | Cuadr√°tica |
| O(2‚Åø) | Backtracking | Exponencial |

```mermaid
graph LR
A[Entrada peque√±a] -->|O(n)| B[Crecimiento lineal]
A -->|O(n¬≤)| C[Crecimiento cuadr√°tico]
A -->|O(2‚Åø)| D[Crecimiento exponencial]
```

```python
import time

def ejemplo_complejidad(n):
    start = time.time()
    total = sum(i for i in range(n))
    print("Tiempo:", round(time.time()-start,6), "seg")
ejemplo_complejidad(10**6)
```

---

## üîπ 0.2. Backtracking (B√∫squeda Exhaustiva con Retroceso)

**Objetivo / Aplicaci√≥n:**
Resolver problemas combinatorios explorando todas las posibilidades, **retrocediendo** cuando una soluci√≥n parcial no puede completarse.

### üìö Fundamento Te√≥rico

**Backtracking** es una t√©cnica algor√≠tmica de **b√∫squeda exhaustiva sistem√°tica** que construye soluciones candidatas de forma incremental y abandona una candidata ("retrocede") tan pronto como determina que no puede conducir a una soluci√≥n v√°lida.

#### Principios Fundamentales:

**1. Espacio de B√∫squeda como √Årbol:**
El backtracking modela el problema como un **√°rbol de decisiones** donde:
- Cada **nodo** representa una decisi√≥n o elecci√≥n parcial
- Cada **rama** representa una opci√≥n disponible
- Las **hojas** son soluciones completas (v√°lidas o inv√°lidas)

**2. Construcci√≥n Incremental:**
La soluci√≥n se construye paso a paso, agregando elementos uno a la vez:
```
Estado actual ‚Üí Elegir candidato ‚Üí Validar ‚Üí Continuar o Retroceder
```

**3. Poda del Espacio de B√∫squeda:**
Se utilizan **restricciones** para eliminar ramas que no pueden conducir a soluciones:
- **Expl√≠citas:** condiciones que debe cumplir toda soluci√≥n
- **Impl√≠citas:** restricciones derivadas del contexto del problema

#### Estructura General del Algoritmo:

```
function BACKTRACK(soluci√≥n_parcial):
    if es_soluci√≥n_completa(soluci√≥n_parcial):
        procesar_soluci√≥n(soluci√≥n_parcial)
        return

    for candidato in generar_candidatos(soluci√≥n_parcial):
        if es_v√°lido(candidato, soluci√≥n_parcial):
            agregar(candidato, soluci√≥n_parcial)
            BACKTRACK(soluci√≥n_parcial)
            remover(candidato, soluci√≥n_parcial)  # RETROCEDER
```

#### An√°lisis de Complejidad:

**Temporal:**
- **Peor caso:** O(b^d) donde:
  - b = factor de ramificaci√≥n (opciones por nivel)
  - d = profundidad del √°rbol (tama√±o de la soluci√≥n)
- Para permutaciones: O(n!)
- Para subconjuntos: O(2‚Åø)

**Espacial:**
- O(d) para la pila de recursi√≥n
- O(n) adicional para la soluci√≥n en construcci√≥n

#### Optimizaciones Comunes:

1. **Ordenamiento de Candidatos:** Elegir primero los m√°s prometedores
2. **Detecci√≥n Temprana:** Identificar soluciones inv√°lidas lo antes posible
3. **Memorizaci√≥n:** Evitar explorar estados ya visitados
4. **Heur√≠sticas:** Guiar la b√∫squeda con informaci√≥n del dominio

#### Aplicaciones Cl√°sicas:

- **N-Reinas:** Colocar N reinas en tablero N√óN sin que se ataquen
- **Sudoku:** Completar cuadr√≠cula con restricciones de fila/columna/regi√≥n
- **Laberinto:** Encontrar caminos desde origen a destino
- **Coloreado de Grafos:** Asignar colores a nodos sin adyacentes iguales
- **Generaci√≥n de Combinaciones/Permutaciones:** Todos los ordenamientos posibles

**Complejidad:** Exponencial en el peor caso O(k‚Åø) ¬∑ **Clasificaci√≥n:** Exacto / Determin√≠stico
**Ejemplo:** Sudoku, N-reinas, combinaciones v√°lidas.

```mermaid
flowchart TD
A[Inicio] --> B[Explorar opci√≥n]
B --> C{Es v√°lida?}
C -->|S√≠| D{Es soluci√≥n completa?}
C -->|No| E[Retroceder]
D -->|S√≠| F[Guardar soluci√≥n]
D -->|No| B
```

```python
def backtrack(sol, nums):
    if len(sol) == len(nums):
        print(sol)
        return
    for n in nums:
        if n not in sol:
            backtrack(sol + [n], nums)

backtrack([], [1,2,3])
```

---

## üîπ 0.3. Branch and Bound (Ramificaci√≥n y Poda)

**Objetivo / Aplicaci√≥n:**
Optimizar la b√∫squeda de soluciones descartando ramas que no pueden mejorar la mejor soluci√≥n actual.
Muy usado en **optimizaci√≥n combinatoria** (p. ej., problema del viajante).

### üìö Fundamento Te√≥rico

**Branch and Bound** es una t√©cnica algor√≠tmica para resolver **problemas de optimizaci√≥n** (minimizaci√≥n o maximizaci√≥n) que combina b√∫squeda exhaustiva con **poda inteligente** basada en cotas (bounds).

#### Principios Fundamentales:

**1. Ramificaci√≥n (Branching):**
- Divide el espacio de soluciones en **subproblemas m√°s peque√±os**
- Construye un **√°rbol de exploraci√≥n** similar a backtracking
- Cada nodo representa un subproblema con restricciones adicionales

**2. Acotaci√≥n (Bounding):**
- Calcula una **cota** (l√≠mite superior o inferior) para cada subproblema
- **Lower bound (LB):** estimaci√≥n optimista del mejor valor alcanzable
- **Upper bound (UB):** mejor soluci√≥n completa encontrada hasta el momento

**3. Poda (Pruning):**
- Si LB de un nodo ‚â• UB actual ‚Üí **podar** esa rama (no puede mejorar)
- Reduce dr√°sticamente el espacio de b√∫squeda sin perder optimalidad

#### Componentes Esenciales:

**a) Estrategia de Selecci√≥n de Nodos:**
- **FIFO (Breadth-First):** Explora por niveles
- **LIFO (Depth-First):** Profundiza primero
- **Best-First:** Elige el nodo con mejor cota
- **Least-Cost:** Prioriza seg√∫n funci√≥n heur√≠stica

**b) Funci√≥n de Acotaci√≥n:**
- Debe ser **admisible:** nunca sobreestimar (minimizaci√≥n) o subestimar (maximizaci√≥n)
- Debe ser **eficiente de calcular**
- Mejor cota ‚Üí m√°s poda ‚Üí menos exploraci√≥n

**c) Soluci√≥n Incumbente:**
- Mejor soluci√≥n **completa** encontrada hasta el momento
- Se actualiza cuando se encuentra una mejor soluci√≥n factible
- Sirve como **upper bound** para poda

#### Algoritmo General:

```
function BRANCH_AND_BOUND(problema):
    mejor_soluci√≥n = ‚àû (minimizaci√≥n) o -‚àû (maximizaci√≥n)
    cola_prioridad = [nodo_ra√≠z]
    
    while cola_prioridad no vac√≠a:
        nodo = extraer_mejor(cola_prioridad)
        
        if cota(nodo) ‚â• mejor_soluci√≥n:  # Poda
            continue
        
        if es_soluci√≥n_completa(nodo):
            if valor(nodo) < mejor_soluci√≥n:
                mejor_soluci√≥n = valor(nodo)
        else:
            for hijo in ramificar(nodo):
                if cota(hijo) < mejor_soluci√≥n:
                    insertar(cola_prioridad, hijo)
    
    return mejor_soluci√≥n
```

#### An√°lisis de Complejidad:

**Temporal:**
- **Peor caso:** O(b^d) exponencial (sin poda efectiva)
- **Caso promedio:** Depende significativamente de la calidad de las cotas
- Poda efectiva puede reducir a O(n¬≤) o O(n¬≥) en problemas espec√≠ficos

**Espacial:**
- O(b¬∑d) para almacenar nodos en cola de prioridad
- Puede ser prohibitivo en problemas grandes

#### Diferencias con Backtracking:

| Aspecto | Backtracking | Branch and Bound |
|---------|--------------|------------------|
| Objetivo | Encontrar **todas** las soluciones o una v√°lida | Encontrar la **√≥ptima** |
| Decisi√≥n de poda | Restricciones de validez | Cotas de optimizaci√≥n |
| Complejidad | O(b^d) sin optimizaci√≥n | Var√≠a seg√∫n calidad de cotas |
| Uso de memoria | Menor (DFS recursivo) | Mayor (cola de nodos) |

#### Aplicaciones Cl√°sicas:

- **Problema del Viajante (TSP):** Encontrar ruta m√°s corta
- **Asignaci√≥n de Tareas:** Minimizar costo total
- **Problema de la Mochila 0/1:** Maximizar valor con peso limitado
- **Job Scheduling:** Minimizar tiempo de finalizaci√≥n
- **Corte de Materiales:** Minimizar desperdicio

**Complejidad:** Exponencial en general ¬∑ **Clasificaci√≥n:** Exacto / Optimizaci√≥n
**Origen:** **Little, Murty, Sweeney y Karel (1963)**.

```mermaid
flowchart TD
A[Inicio] --> B[Generar nodo ra√≠z]
B --> C[Expandir nodo actual]
C --> D[Evaluar l√≠mite inferior]
D --> E{Supera mejor soluci√≥n?}
E -->|S√≠| F[Poda rama]
E -->|No| G[Explorar hijos]
```

```python
def branch_and_bound(nodos, mejor=float("inf")):
    for nodo in nodos:
        if nodo >= mejor:
            continue
        if nodo == 7:
            mejor = min(mejor, nodo)
        else:
            mejor = branch_and_bound([nodo+1, nodo+2], mejor)
    return mejor

print("Mejor valor encontrado:", branch_and_bound([0]))
```

---

## üîπ 0.4. Programaci√≥n Din√°mica

**Objetivo / Aplicaci√≥n:**
Dividir un problema en **subproblemas solapados**, resolviendo cada uno una vez y reutilizando sus resultados.
Se aplica en optimizaci√≥n, secuencias, rutas, etc.

### üìö Fundamento Te√≥rico

La **Programaci√≥n Din√°mica (DP)** es un paradigma algor√≠tmico que resuelve problemas complejos dividi√©ndolos en **subproblemas m√°s simples**, almacenando sus soluciones para evitar recalcularlas. Transforma algoritmos exponenciales en polinomiales al eliminar redundancia computacional.

#### Principios Fundamentales:

**1. Subestructura √ìptima:**
Un problema tiene subestructura √≥ptima si su **soluci√≥n √≥ptima** se puede construir eficientemente a partir de las **soluciones √≥ptimas** de sus subproblemas.

**Ejemplo matem√°tico:**
```
Camino m√°s corto: dist(A‚ÜíC) = dist(A‚ÜíB) + dist(B‚ÜíC)
Solo es √≥ptimo si A‚ÜíB y B‚ÜíC tambi√©n son √≥ptimos
```

**2. Subproblemas Solapados:**
Los subproblemas se **repiten m√∫ltiples veces** durante la resoluci√≥n recursiva.
Sin memorizaci√≥n, cada subproblema se resuelve m√∫ltiples veces ‚Üí ineficiencia exponencial.
Con memorizaci√≥n, cada subproblema se resuelve **una sola vez** ‚Üí eficiencia polinomial.

**Contraste con Divide y Vencer√°s:**
- **D&C:** Subproblemas **independientes** (no se solapan)
- **DP:** Subproblemas **solapados** (se reutilizan)

#### Enfoques de Implementaci√≥n:

**1. Top-Down (Memorizaci√≥n):**
- Comienza desde el problema original
- Resuelve recursivamente los subproblemas
- **Almacena** (memoriza) resultados en tabla/diccionario
- Calcula subproblemas **bajo demanda**

```python
def fib_memo(n, memo={}):
    if n in memo:
        return memo[n]  # Ya calculado
    if n <= 1:
        return n
    memo[n] = fib_memo(n-1, memo) + fib_memo(n-2, memo)
    return memo[n]
```

**Ventajas:** Intuitivo, solo calcula lo necesario
**Desventajas:** Overhead de recursi√≥n, stack overflow posible

**2. Bottom-Up (Tabulaci√≥n):**
- Comienza desde los casos base m√°s simples
- Resuelve subproblemas en **orden topol√≥gico**
- Construye tabla iterativamente
- Calcula **todos** los subproblemas

```python
def fib_tabular(n):
    dp = [0] * (n+1)
    dp[1] = 1
    for i in range(2, n+1):
        dp[i] = dp[i-1] + dp[i-2]
    return dp[n]
```

**Ventajas:** M√°s eficiente (sin recursi√≥n), predecible
**Desventajas:** Puede calcular subproblemas innecesarios

#### Estructura de la Relaci√≥n de Recurrencia:

El coraz√≥n de DP es la **ecuaci√≥n de recurrencia** que expresa la soluci√≥n en funci√≥n de subproblemas:

```
DP[estado] = funci√≥n(DP[sub_estado_1], DP[sub_estado_2], ...)
```

**Ejemplo - Fibonacci:**
```
F(n) = F(n-1) + F(n-2)
Base: F(0)=0, F(1)=1
```

**Ejemplo - Mochila 0/1:**
```
DP[i][w] = max(
    DP[i-1][w],              // No tomar item i
    valor[i] + DP[i-1][w-peso[i]]  // Tomar item i
)
```

#### Pasos para Dise√±ar una Soluci√≥n DP:

1. **Identificar subproblemas:** ¬øQu√© estados definen un subproblema?
2. **Definir recurrencia:** ¬øC√≥mo se relacionan los estados?
3. **Establecer casos base:** ¬øCu√°les son los subproblemas triviales?
4. **Determinar orden de evaluaci√≥n:** ¬øEn qu√© orden calcular los estados?
5. **Optimizar espacio:** ¬øSe pueden descartar estados antiguos?

#### An√°lisis de Complejidad:

**Temporal:**
- **F√≥rmula general:** O(#subproblemas √ó tiempo_por_subproblema)
- **Fibonacci:** O(n) vs O(2‚Åø) recursivo puro
- **Mochila 0/1:** O(n¬∑W) donde n=items, W=capacidad
- **LCS (Longest Common Subsequence):** O(m¬∑n)

**Espacial:**
- **Completo:** O(dimensiones del estado)
- **Optimizado:** A menudo reducible a O(tama√±o de una fila/columna)

#### Optimizaci√≥n de Espacio:

Muchos problemas DP solo necesitan **resultados recientes**:

```python
# Espacio O(n)
dp = [0] * n
for i in range(n):
    dp[i] = dp[i-1] + dp[i-2]

# Optimizado a O(1)
prev2, prev1 = 0, 1
for i in range(n):
    current = prev1 + prev2
    prev2, prev1 = prev1, current
```

#### Variantes y Extensiones:

1. **DP con Bitmasking:** Estados representados como bits (Problema del Viajante)
2. **DP en √Årboles:** Problemas en estructuras jer√°rquicas
3. **DP con Optimizaci√≥n Convexa:** Monoton√≠a en decisiones √≥ptimas
4. **DP Probabil√≠stica:** Con estados estoc√°sticos

#### Aplicaciones Cl√°sicas:

- **Secuencias:** LCS, LIS (Longest Increasing Subsequence), Edit Distance
- **Caminos:** Matriz de costos m√≠nimos, Floyd-Warshall
- **Optimizaci√≥n:** Mochila, Coin Change, Partici√≥n de arrays
- **Juegos:** Nim, Minimax con DP
- **Strings:** Pattern Matching, Expresiones Regulares

**Complejidad:** O(n¬∑m) ¬∑ **Clasificaci√≥n:** Determin√≠stico / Optimizaci√≥n / Recursivo
**Origen:** **Richard Bellman (1950s)**.

```mermaid
flowchart TD
A[Problema grande] --> B[Dividir en subproblemas]
B --> C[Resolver subproblemas menores]
C --> D[Almacenar resultados (memo)]
D --> E[Combinar resultados parciales]
```

### Ejemplo: Fibonacci con memorizaci√≥n

```python
memo = {}
def fib(n):
    if n in memo:
        return memo[n]
    if n <= 1:
        return n
    memo[n] = fib(n-1) + fib(n-2)
    return memo[n]

print("Fibonacci(10) =", fib(10))
```

---

### Ejemplo: Problema de la Mochila (0/1 Knapsack)

```python
def knapsack(pesos, valores, W):
    n = len(pesos)
    dp = [[0]*(W+1) for _ in range(n+1)]
    for i in range(1,n+1):
        for w in range(W+1):
            if pesos[i-1] <= w:
                dp[i][w] = max(dp[i-1][w], valores[i-1]+dp[i-1][w-pesos[i-1]])
            else:
                dp[i][w] = dp[i-1][w]
    return dp[n][W]

print("Valor m√°ximo:", knapsack([2,3,4],[4,5,6],5))
```

---

## üîπ 0.5. Divide y Vencer√°s

**Objetivo / Aplicaci√≥n:**
Resolver un problema grande dividi√©ndolo en **subproblemas independientes**, resolvi√©ndolos y combinando los resultados.

### üìö Fundamento Te√≥rico

**Divide y Vencer√°s** (Divide and Conquer) es un paradigma algor√≠tmico que descompone un problema en **subproblemas m√°s peque√±os del mismo tipo**, los resuelve recursivamente, y luego **combina** sus soluciones para obtener la soluci√≥n del problema original.

#### Principios Fundamentales:

**1. Divisi√≥n (Divide):**
- Descomponer el problema en k **subproblemas m√°s peque√±os**
- Los subproblemas son **instancias del mismo problema**
- T√≠picamente k=2 (divisi√≥n binaria), pero puede variar

**2. Conquista (Conquer):**
- Resolver cada subproblema **recursivamente**
- Si el subproblema es suficientemente peque√±o ‚Üí resolver directamente (caso base)
- Los subproblemas son **independientes** entre s√≠

**3. Combinaci√≥n (Combine):**
- **Fusionar** las soluciones de los subproblemas
- Construir la soluci√≥n del problema original
- Puede ser trivial (MergeSort) o compleja (Strassen)

#### Estructura Recursiva General:

```python
def divide_y_venceras(problema):
    # Caso base
    if es_peque√±o(problema):
        return resolver_directamente(problema)
    
    # Dividir
    subproblemas = dividir(problema)
    
    # Conquistar (recursi√≥n)
    soluciones_parciales = []
    for subproblema in subproblemas:
        soluciones_parciales.append(divide_y_venceras(subproblema))
    
    # Combinar
    return combinar(soluciones_parciales)
```

#### An√°lisis de Complejidad mediante Teorema Maestro:

Para recurrencias de la forma:
```
T(n) = a¬∑T(n/b) + f(n)
```
Donde:
- $a$ = n√∫mero de subproblemas
- $n/b$ = tama√±o de cada subproblema
- $f(n)$ = costo de dividir y combinar

**Casos del Teorema Maestro:**

**Caso 1:** Si $f(n) = O(n^c)$ donde $c < log_b(a)$
```
T(n) = Œò(n^(log_b(a)))
```

**Caso 2:** Si $f(n) = Œò(n^c ¬∑ log^k(n))$ donde $c = log_b(a)$
```
T(n) = Œò(n^c ¬∑ log^(k+1)(n))
```

**Caso 3:** Si $f(n) = Œ©(n^c)$ donde $c > log_b(a)$
```
T(n) = Œò(f(n))
```

#### Ejemplos de Aplicaci√≥n del Teorema:

**MergeSort:** $T(n) = 2T(n/2) + O(n)$
- $a=2$, $b=2$, $f(n)=n$ ‚Üí $c=1$, $log‚ÇÇ(2)=1$
- Caso 2: $T(n) = Œò(n log n)$

**B√∫squeda Binaria:** $T(n) = T(n/2) + O(1)$
- $a=1$, $b=2$, $f(n)=1$ ‚Üí $c=0$, $log‚ÇÇ(1)=0$
- Caso 2: $T(n) = Œò(log n)$

**Multiplicaci√≥n de Karatsuba:** $T(n) = 3T(n/2) + O(n)$
- $a=3$, $b=2$, $f(n)=n$ ‚Üí $c=1$, $log‚ÇÇ(3)‚âà1.585$
- Caso 1: $T(n) = Œò(n^1.585)$

#### Diferencias con Programaci√≥n Din√°mica:

| Aspecto | Divide y Vencer√°s | Programaci√≥n Din√°mica |
|---------|-------------------|----------------------|
| Subproblemas | **Independientes** | **Solapados** |
| Almacenamiento | No necesita memorizaci√≥n | Requiere tabla/memo |
| Recursi√≥n | Pura (tree recursion) | Con memorizaci√≥n |
| Ejemplos | MergeSort, QuickSort | Fibonacci, Knapsack |

#### Estrategias de Divisi√≥n:

**1. Divisi√≥n Balanceada:**
- Dividir en partes **aproximadamente iguales**
- Garantiza profundidad logar√≠tmica
- Ejemplo: MergeSort (n/2, n/2)

**2. Divisi√≥n Desbalanceada:**
- Una parte significativamente m√°s grande
- Puede degradar a O(n¬≤)
- Ejemplo: QuickSort con pivote malo

**3. Divisi√≥n M√∫ltiple:**
- M√°s de 2 subproblemas
- Ejemplo: QuickSort con 3 particiones (< pivote, = pivote, > pivote)

#### Optimizaciones Comunes:

**1. Cambio a Algoritmo Simple para Casos Peque√±os:**
```python
def merge_sort_optimizado(arr):
    if len(arr) < 10:  # Umbral
        return insertion_sort(arr)  # M√°s r√°pido para n peque√±o
    # ... continuar con merge sort
```

**2. Reducci√≥n de Overhead:**
- Evitar copias innecesarias de arrays
- Usar √≠ndices en lugar de subarrays

**3. Paralelizaci√≥n:**
- Los subproblemas independientes se pueden resolver en paralelo
- Ideal para sistemas multi-core

#### Complejidad Espacial:

**Stack de Recursi√≥n:**
- Profundidad m√°xima: O(log n) para divisi√≥n balanceada
- Cada llamada almacena: variables locales + par√°metros
- Total: O(log n) espacio de stack

**Memoria Auxiliar:**
- MergeSort: O(n) para array temporal
- QuickSort in-place: O(1) adicional
- Strassen: O(n¬≤) matrices temporales

#### Aplicaciones Cl√°sicas:

**Ordenamiento:**
- MergeSort: O(n log n) garantizado, estable
- QuickSort: O(n log n) promedio, in-place

**B√∫squeda:**
- B√∫squeda Binaria: O(log n) en arrays ordenados
- Selecci√≥n del k-√©simo elemento: O(n) promedio

**Geometr√≠a Computacional:**
- Par m√°s cercano: O(n log n)
- Envolvente convexa: O(n log n)

**√Ålgebra:**
- Multiplicaci√≥n de matrices (Strassen): O(n^2.807)
- FFT (Fast Fourier Transform): O(n log n)
- Multiplicaci√≥n de enteros grandes (Karatsuba): O(n^1.585)

**Procesamiento:**
- Maximum Subarray (Kadane adaptado): O(n log n)
- Inversiones en arrays: O(n log n)

**Complejidad:** O(n log n) (en casos balanceados) ¬∑ **Clasificaci√≥n:** Recursivo / Determin√≠stico

```mermaid
flowchart TD
A[Problema grande] --> B[Dividir en subproblemas]
B --> C[Resolver subproblemas recursivamente]
C --> D[Combinar resultados]
D --> E[Soluci√≥n final]
```

```python
def merge_sort(arr):
    if len(arr) <= 1: return arr
    mid = len(arr)//2
    izq = merge_sort(arr[:mid])
    der = merge_sort(arr[mid:])
    return sorted(izq + der)

print(merge_sort([5,3,8,1,2]))
```

---

## üîπ 0.6. Algoritmos Probabil√≠sticos (Monte Carlo / Las Vegas)

**Objetivo / Aplicaci√≥n:**
Resolver problemas complejos mediante **aleatoriedad controlada**.
- **Monte Carlo:** puede devolver respuestas incorrectas, pero r√°pido.
- **Las Vegas:** siempre correcto, pero tiempo variable.

### üìö Fundamento Te√≥rico

Los **algoritmos probabil√≠sticos** (o randomizados) utilizan **decisiones aleatorias** durante su ejecuci√≥n para resolver problemas de forma eficiente. A diferencia de los algoritmos determin√≠sticos, su comportamiento puede variar entre ejecuciones con la misma entrada.

#### Clasificaci√≥n Principal:

**1. Algoritmos Monte Carlo:**
- **Tiempo de ejecuci√≥n:** Determin√≠stico o acotado
- **Resultado:** Puede ser incorrecto con probabilidad Œµ (error bounded)
- **Compromiso:** Velocidad vs Exactitud
- **Estrategia:** Ejecutar m√∫ltiples veces y tomar consenso

**Caracter√≠sticas:**
```
P(respuesta correcta) ‚â• 1 - Œµ
```
- Al repetir k veces, error disminuye exponencialmente: Œµ^k
- √ötil cuando verificar es m√°s f√°cil que resolver

**Ejemplos:**
- Test de primalidad de Miller-Rabin
- Aproximaci√≥n de integrales complejas
- Conteo aproximado en streams

**2. Algoritmos Las Vegas:**
- **Tiempo de ejecuci√≥n:** Aleatorio (var√≠a entre ejecuciones)
- **Resultado:** Siempre correcto (cuando termina)
- **Compromiso:** Correcci√≥n garantizada vs Tiempo variable
- **Estrategia:** Repetir si toma demasiado tiempo

**Caracter√≠sticas:**
```
P(terminaci√≥n en tiempo T) ‚â• 1 - Œ¥
```
- Tiempo esperado es polinomial
- Nunca devuelve respuesta incorrecta

**Ejemplos:**
- QuickSort con pivote aleatorio
- Algoritmo de Rabin-Karp para pattern matching
- Random walk en grafos

#### Comparaci√≥n Directa:

| Aspecto | Monte Carlo | Las Vegas |
|---------|-------------|-----------|
| Correcci√≥n | **Probabil√≠stica** | **Garantizada** |
| Tiempo | Fijo o acotado | **Variable** |
| Aplicaci√≥n | Cuando error tolerable | Cuando correcci√≥n cr√≠tica |
| Mejora | Repetir y promediar | Reintentar si lento |

#### Fundamentos Matem√°ticos:

**1. Teorema del L√≠mite Central:**
Al promediar n muestras aleatorias, la distribuci√≥n converge a normal:
```
Media muestral ~ N(Œº, œÉ¬≤/n)
```
Error est√°ndar disminuye como 1/‚àön

**2. Desigualdad de Chernoff:**
Para suma de variables aleatorias independientes:
```
P(|X - E[X]| ‚â• Œ¥¬∑E[X]) ‚â§ 2¬∑e^(-Œ¥¬≤¬∑E[X]/3)
```
Probabilidad de desviaci√≥n grande decae exponencialmente

**3. M√©todo de Momentos:**
Estimar distribuci√≥n comparando momentos muestrales con te√≥ricos:
```
m_k = E[X^k]
```

#### T√©cnicas de Reducci√≥n de Varianza:

**1. Sampling Estratificado:**
- Dividir espacio en regiones homog√©neas
- Muestrear proporcionalmente de cada regi√≥n
- Reduce varianza manteniendo sesgo

**2. Variables Antit√©ticas:**
- Usar pares de muestras correlacionadas negativamente
- X y (1-X) para reducir varianza

**3. Control Variates:**
- Usar variable correlacionada con respuesta conocida
- Ajustar estimaci√≥n bas√°ndose en diferencia

#### Generaci√≥n de N√∫meros Aleatorios:

**Pseudo-aleatoriedad:**
- Generadores congruenciales lineales (LCG)
- Mersenne Twister (per√≠odo 2^19937-1)
- Xorshift, PCG (modernos, r√°pidos)

**Pruebas de Aleatoriedad:**
- œá¬≤ test para uniformidad
- Runs test para independencia
- Spectral test para correlaci√≥n

#### An√°lisis de Complejidad:

**Temporal:**
- **Monte Carlo:** O(f(n)) donde f es tiempo de una iteraci√≥n
- **Las Vegas:** E[T] = tiempo esperado, puede variar
- Repetir k veces Monte Carlo: k¬∑O(f(n))

**Espacial:**
- T√≠picamente O(1) o O(log n)
- No requiere almacenar muestras anteriores

**Probabilidad de Error:**
- **Monte Carlo:** Œµ por ejecuci√≥n, Œµ^k al repetir k veces
- **Las Vegas:** 0 (siempre correcto)

#### Aplicaciones por Dominio:

**1. Integraci√≥n Num√©rica:**
```python
# Integral de funci√≥n compleja en dominio irregular
def monte_carlo_integral(f, a, b, n=10000):
    samples = uniform(a, b, n)
    return (b-a) * mean([f(x) for x in samples])
```

**2. Optimizaci√≥n:**
- Simulated Annealing: Escapar m√≠nimos locales
- Genetic Algorithms: B√∫squeda en espacios grandes
- Random Restart: Diversificar soluciones

**3. Aprendizaje Autom√°tico:**
- Dropout en redes neuronales
- Stochastic Gradient Descent
- Bootstrap aggregating (Bagging)

**4. Criptograf√≠a:**
- Generaci√≥n de claves RSA
- Protocolos de commitment
- Zero-knowledge proofs

**5. Verificaci√≥n:**
- Fingerprinting de polinomios
- Verificaci√≥n de identidades matriciales
- Protocol testing

#### Ventajas de la Aleatoriedad:

**1. Simplicidad:**
- Algoritmos m√°s simples que determin√≠sticos
- Menos casos especiales

**2. Eficiencia:**
- Pueden romper barreras de complejidad determin√≠stica
- Ejemplo: Verificaci√≥n de identidad matricial O(n¬≤) vs O(n^2.373)

**3. Robustez:**
- Resistentes a inputs adversariales
- No hay "peor caso" explotable

**4. Paralelizaci√≥n:**
- Muestras independientes ‚Üí f√°cil paralelizar
- Escalabilidad natural

#### Limitaciones y Consideraciones:

**1. Reproducibilidad:**
- Dif√≠cil depurar (comportamiento no determin√≠stico)
- Soluci√≥n: Semillas fijas en testing

**2. Calidad del RNG:**
- Generadores malos ‚Üí resultados sesgados
- Importante usar implementaciones robustas

**3. An√°lisis Te√≥rico:**
- Probar correcci√≥n m√°s complejo
- Requiere teor√≠a de probabilidad avanzada

**4. Entornos Cr√≠ticos:**
- No aceptable en sistemas cr√≠ticos (aeron√°utica, medicina)
- Preferir determin√≠sticos con garant√≠as

#### Algoritmos H√≠bridos:

Combinan estrategias determin√≠sticas y probabil√≠sticas:

**1. Derandomization:**
- Convertir algoritmo aleatorio en determin√≠stico
- M√©todo: Buscar exhaustivamente "buenas" semillas

**2. Boosting:**
- Convertir algoritmo con error 1/2-Œµ en error arbitrariamente peque√±o
- Repetir y votar por mayor√≠a

**3. Amplification:**
- Reducir probabilidad de error exponencialmente
- Ejecutar m√∫ltiples veces independientes

**Complejidad:** Depende de distribuci√≥n aleatoria ¬∑ **Clasificaci√≥n:** Probabil√≠stico / Aproximado

```mermaid
flowchart TD
A[Generar muestra aleatoria] --> B[Evaluar funci√≥n objetivo]
B --> C[Promediar resultados]
C --> D[Estimar soluci√≥n con probabilidad de error]
```

### Ejemplo Monte Carlo: estimar œÄ

```python
import random, math

def montecarlo_pi(n=10000):
    dentro = 0
    for _ in range(n):
        x,y = random.random(), random.random()
        if x*x + y*y <= 1:
            dentro += 1
    return 4*dentro/n

print("Estimaci√≥n de œÄ:", montecarlo_pi())
```

---

### ‚úÖ Cierre de la Secci√≥n 10

Los **algoritmos te√≥ricos** constituyen la base del pensamiento algor√≠tmico moderno:
- **Backtracking / Branch & Bound:** b√∫squeda exhaustiva y optimizaci√≥n.
- **Programaci√≥n Din√°mica:** reutilizaci√≥n eficiente.
- **Divide & Vencer√°s:** resoluci√≥n modular.
- **Probabil√≠sticos:** soluciones r√°pidas con incertidumbre controlada.

La **teor√≠a de la complejidad** permite entender sus l√≠mites y elegir la estrategia m√°s adecuada para cada tipo de problema.

---
